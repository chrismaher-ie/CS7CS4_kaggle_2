{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Get_Clean_Combined_Dataset():\n",
    "\n",
    "    df = pd.read_csv(\"tcd-ml-1920-group-income-train.csv\")\n",
    "    df\n",
    "    \n",
    "    df.drop_duplicates(subset =\"Instance\", \n",
    "                     keep = False, inplace = True)\n",
    "    df2 = pd.read_csv(\"tcd-ml-1920-group-income-test.csv\")\n",
    "    df2[\"Instance\"] = df2[\"Instance\"] + 991709\n",
    "    \n",
    "    data = pd.concat([df,df2], axis=0)\n",
    "    data = data.reset_index(drop=True)\n",
    "    data['Yearly Income in addition to Salary (e.g. Rental Income)'] = data['Yearly Income in addition to Salary (e.g. Rental Income)'].str.replace(' EUR', '').astype(float)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_set = Get_Clean_Combined_Dataset()\n",
    "data_set[\"Total Yearly Income [EUR]\"] = data_set[\"Total Yearly Income [EUR]\"] - data_set[\"Yearly Income in addition to Salary (e.g. Rental Income)\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Split data into income set (Incuding instance so that the unlabled data can extracted later)\n",
    "y = data_set[[\"Instance\",\"Total Yearly Income [EUR]\",\"Yearly Income in addition to Salary (e.g. Rental Income)\"]].copy()\n",
    "\n",
    "#And all the Feature data (Incuding instance so that the unlabled data can extracted later)\n",
    "X = data_set[[\"Instance\",\"Year of Record\",\"Age\"]].copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to relpace invalid entries in numeric features with the mean walue of the particular feature\n",
    "def ReplaceNan_Numeric(df,F_Name):\n",
    "    average = df[F_Name].dropna().mean(axis=0)\n",
    "    df[F_Name] = df[F_Name].replace(np.nan, average, inplace=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MinMaxScale_Feature(df, F_Name):\n",
    "    feature_array = df[F_Name].to_numpy()\n",
    "    feature_array = feature_array.reshape(-1, 1)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_array = scaler.fit_transform(feature_array)\n",
    "    \n",
    "    scaled_df = pd.DataFrame(scaled_array)\n",
    "    df = df.drop(F_Name,1)   #Feature Matrix\n",
    "    new_df = pd.concat([df, scaled_df], axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean numeric data\n",
    "X = ReplaceNan_Numeric(X,\"Year of Record\")\n",
    "X = ReplaceNan_Numeric(X,\"Age\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numeric data\n",
    "X = MinMaxScale_Feature(X,\"Year of Record\")\n",
    "X = MinMaxScale_Feature(X,\"Age\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data back out to separate sets on key 'Instance'\n",
    "df2_X = X.loc[X[\"Instance\"] > 991709]\n",
    "X = X.loc[X[\"Instance\"] <= 991709]         \n",
    "df2_y = y.loc[y[\"Instance\"] > 991709]\n",
    "y = y.loc[y[\"Instance\"] <= 991709]\n",
    "\n",
    "#Drop 'Instance' from datasets now that it is no longer needed as a key\n",
    "df2_X = df2_X.drop(\"Instance\",1)\n",
    "X = X.drop(\"Instance\",1)\n",
    "y = y.drop(\"Instance\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "add_income = y_test[\"Yearly Income in addition to Salary (e.g. Rental Income)\"].values\n",
    "\n",
    "y_train = y_train.drop(\"Yearly Income in addition to Salary (e.g. Rental Income)\",1)\n",
    "y_test = y_test.drop(\"Yearly Income in addition to Salary (e.g. Rental Income)\",1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create ridgecv regression object with 4 crossvalidation folds\n",
    "regr = RidgeCV(alphas=np.array([0.0001,0.001,0.01,0.1,1]),fit_intercept=True,normalize=False,cv = 4)\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_income = add_income.reshape(-1,1)\n",
    "y_pred = np.add(y_pred,add_income)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the unlabled dataset\n",
    "df2_y_pred = regr.predict(df2_X)\n",
    "# export data\n",
    "pd.DataFrame(df2_y_pred).to_csv(\"Predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
