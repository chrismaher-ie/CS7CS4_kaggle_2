{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder, KBinsDiscretizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Get_Clean_Combined_Dataset():\n",
    "\n",
    "    df = pd.read_csv(\"tcd-ml-1920-group-income-train.csv\")\n",
    "    df\n",
    "    \n",
    "    df.drop_duplicates(subset =\"Instance\", \n",
    "                     keep = False, inplace = True)\n",
    "    df2 = pd.read_csv(\"tcd-ml-1920-group-income-test.csv\")\n",
    "    df2[\"Instance\"] = df2[\"Instance\"] + 991709\n",
    "    \n",
    "    data = pd.concat([df,df2], axis=0)\n",
    "    data = data.reset_index(drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_set = Get_Clean_Combined_Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Split data into income set (Incuding instance so that the unlabled data can extracted later)\n",
    "y = data_set[[\"Instance\",\"Total Yearly Income [EUR]\"]].copy()\n",
    "data_set.head()\n",
    "\n",
    "#And all the Feature data (Incuding instance so that the unlabled data can extracted later)\n",
    "X = data_set[[\"Instance\",\"Year of Record\",\"Age\",\"Size of City\",\"Profession\",\"University Degree\",\"Country\",\"Gender\"]].copy()\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to relpace invalid entries in numeric features with the mean walue of the particular feature\n",
    "def ReplaceNan_Numeric(df,F_Name):\n",
    "    average = df[F_Name].dropna().mean(axis=0)\n",
    "    df[F_Name] = df[F_Name].replace(np.nan, average, inplace=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to onehot encode catagorical features\n",
    "def oneHotEncode_Feature(df,F_Name):\n",
    "    feature = df[F_Name]\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(feature)\n",
    "    \n",
    "    #binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "    feature_onehot = pd.DataFrame(onehot_encoded)\n",
    "    df = df.drop(F_Name,1)   #Feature Matrix\n",
    "    new_df = pd.concat([df, feature_onehot], axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to onehot encode catagorical features\n",
    "def LabelEncode_Feature(df,F_Name):\n",
    "    feature = df[F_Name]\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(feature)\n",
    "\n",
    "    feature_e = pd.DataFrame(integer_encoded)\n",
    "    \n",
    "    df = df.drop(F_Name,1)   #Feature Matrix\n",
    "    new_df = pd.concat([df, feature_e], axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert non-linear numeric data into 'bins' of nearby values, bins represented with onehot encoding\n",
    "def KBins_Feature(df, F_Name):\n",
    "    feature_array = df[F_Name].to_numpy()\n",
    "    feature_array = feature_array.reshape(-1, 1)\n",
    "    est = KBinsDiscretizer(n_bins=8, encode='onehot-dense', strategy='quantile')\n",
    "    est.fit(feature_array)\n",
    "    onehot_encoded = est.transform(feature_array)\n",
    "    \n",
    "    onehot_feature_df = pd.DataFrame(onehot_encoded)\n",
    "    df = df.drop(F_Name,1)   #Feature Matrix\n",
    "    new_df = pd.concat([df, onehot_feature_df], axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MinMaxScale_Feature(df, F_Name):\n",
    "    feature_array = df[F_Name].to_numpy()\n",
    "    feature_array = feature_array.reshape(-1, 1)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_array = scaler.fit_transform(feature_array)\n",
    "    \n",
    "    scaled_df = pd.DataFrame(scaled_array)\n",
    "    df = df.drop(F_Name,1)   #Feature Matrix\n",
    "    new_df = pd.concat([df, scaled_df], axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean numeric data\n",
    "X = ReplaceNan_Numeric(X,\"Year of Record\")\n",
    "X = ReplaceNan_Numeric(X,\"Age\")\n",
    "X = ReplaceNan_Numeric(X,\"Size of City\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numeric data\n",
    "X = MinMaxScale_Feature(X,\"Year of Record\")\n",
    "X = MinMaxScale_Feature(X,\"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Size of cities into bins \n",
    "X = KBins_Feature(X,\"Size of City\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean and onehot encode categorical features\n",
    "X[\"Profession\"] = X[\"Profession\"].replace(np.nan, \"Unknown\", inplace=False)\n",
    "X = LabelEncode_Feature(X,\"Profession\")\n",
    "\n",
    "X[\"Gender\"] = X[\"Gender\"].replace(np.nan, \"unknown\", inplace=False)\n",
    "X = LabelEncode_Feature(X,\"Gender\")\n",
    "\n",
    "X[\"Country\"] =  X[\"Country\"].replace(np.nan, \"Unknown\", inplace=False)\n",
    "X = oneHotEncode_Feature(X,\"Country\")\n",
    "\n",
    "X[\"University Degree\"] = X[\"University Degree\"].replace(np.nan, \"Unknown\", inplace=False)\n",
    "X = LabelEncode_Feature(X,\"University Degree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data back out to separate sets on key 'Instance'\n",
    "df2_X = X.loc[X[\"Instance\"] > 991709]\n",
    "X = X.loc[X[\"Instance\"] <= 991709]         \n",
    "#df2_y = y.loc[y[\"Instance\"] > 991709] #not needed\n",
    "y = y.loc[y[\"Instance\"] <= 991709]\n",
    "\n",
    "#Drop 'Instance' from datasets not that it is nolonger needed as a key\n",
    "df2_X = df2_X.drop(\"Instance\",1)\n",
    "X = X.drop(\"Instance\",1)\n",
    "y = y.drop(\"Instance\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create ridgecv regression object with 4 crossvalidation folds\n",
    "regr = BayesianRidge()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, (y_train))\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# Print results\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(y_test, (y_pred)))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, (y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the unlabled dataset\n",
    "df2_y_pred = regr.predict(df2_X)\n",
    "# export data\n",
    "pd.DataFrame(df2_y_pred).to_csv(\"Predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
